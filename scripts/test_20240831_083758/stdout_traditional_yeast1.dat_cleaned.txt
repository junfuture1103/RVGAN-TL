Started testing RGAN-TL Classifier : ../data/testarff/yeast1.dat_cleaned.arff
====== arff datasets ======
[[0.53932583 0.5402299  0.35443038 ... 0.         0.72602737 0.31      ]
 [0.38202247 0.49425286 0.37974685 ... 0.         0.73972607 0.22      ]
 [0.5168539  0.42528737 0.24050635 ... 0.         0.6438356  0.22      ]
 ...
 [0.38202247 0.45977008 0.37974685 ... 0.         0.71232873 0.22      ]
 [0.33707863 0.3678161  0.31645572 ... 0.         0.6849315  0.7       ]
 [0.494382   0.31034482 0.51898736 ... 0.         0.50684935 0.28      ]]
123     0
432     0
1033    0
529     1
1417    0
       ..
1130    0
1294    0
860     0
1459    0
1126    1
Name: Class, Length: 1484, dtype: int64
============ LGBM ============
[LightGBM] [Info] Number of positive: 258, number of negative: 632
[LightGBM] [Info] Total Bins 307
[LightGBM] [Info] Number of data points in the train set: 890, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289888 -> initscore=-0.895930
[LightGBM] [Info] Start training from score -0.895930
Accuracy :  0.7912
Precision :  0.7374
Recall :  0.4269
f1-score :  0.5407
g_mean :  0.633
auc :  0.6827
============ START SMOTE ============
============ DONE SMOTE ============
[LightGBM] [Info] Number of positive: 632, number of negative: 632
[LightGBM] [Info] Total Bins 1483
[LightGBM] [Info] Number of data points in the train set: 1264, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
Accuracy :  0.7525
Precision :  0.5561
Recall :  0.6959
f1-score :  0.6182
g_mean :  0.7346
auc :  0.7357
============ START ADASYN ============
============ DONE ADASYN ============
[LightGBM] [Info] Number of positive: 683, number of negative: 632
[LightGBM] [Info] Total Bins 1476
[LightGBM] [Info] Number of data points in the train set: 1315, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519392 -> initscore=0.077605
[LightGBM] [Info] Start training from score 0.077605
Accuracy :  0.7424
Precision :  0.5381
Recall :  0.7427
f1-score :  0.6241
g_mean :  0.7425
auc :  0.7425
============ START ROS ============
============ DONE ROS ============
[LightGBM] [Info] Number of positive: 632, number of negative: 632
[LightGBM] [Info] Total Bins 318
[LightGBM] [Info] Number of data points in the train set: 1264, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
Accuracy :  0.7492
Precision :  0.5505
Recall :  0.7018
f1-score :  0.617
g_mean :  0.7343
auc :  0.735
============ START BorderlineSMOTE ============
============ DONE BorderlineSMOTE ============
[LightGBM] [Info] Number of positive: 632, number of negative: 632
[LightGBM] [Info] Total Bins 1477
[LightGBM] [Info] Number of data points in the train set: 1264, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
Accuracy :  0.7559
Precision :  0.5575
Recall :  0.7368
f1-score :  0.6347
g_mean :  0.7501
auc :  0.7502
============ START IForest ============
Accuracy :  0.6785
Precision :  0.3387
Recall :  0.1228
f1-score :  0.1802
g_mean :  0.333
auc :  0.5129
============ DONE IForest ============
============ START IForest ============
[-0.16576489 -0.14309151 -0.20739304 -0.1544842  -0.13926142 -0.14256573
 -0.15611133 -0.1435236  -0.19056195 -0.18223056 -0.16423916 -0.14114086
 -0.14687705 -0.14642098 -0.14505864 -0.20020264 -0.14411312 -0.17551399
 -0.14400677 -0.16624393 -0.17790765 -0.19172421 -0.14472976 -0.17122409
 -0.19586034 -0.16679116 -0.16533386 -0.23046462 -0.15602501 -0.17958372
 -0.14696653 -0.1625758  -0.1550623  -0.14077834 -0.14765659 -0.1617129
 -0.13940116 -0.16255601 -0.13798712 -0.1380353  -0.14650224 -0.35081185
 -0.15172587 -0.14604487 -0.14178996 -0.17243096 -0.14799411 -0.14492362
 -0.14803016 -0.19740113 -0.14444922 -0.14361697 -0.1399885  -0.16845026
 -0.13829389 -0.1356601  -0.14597704 -0.17184053 -0.14267852 -0.15894491
 -0.14980423 -0.16479189 -0.15924256 -0.14671061 -0.14570157 -0.16703389
 -0.17107065 -0.15663799 -0.14126795 -0.17089608 -0.14521056 -0.13915146
 -0.22384921 -0.17237269 -0.18639674 -0.15042536 -0.16274156 -0.14466744
 -0.14407997 -0.14043149 -0.13986751 -0.25779978 -0.13759007 -0.14695805
 -0.18780649 -0.17558913 -0.15128897 -0.14301652 -0.14061398 -0.13991883
 -0.14253473 -0.14173067 -0.34660076 -0.14330338 -0.1515721  -0.13601125
 -0.14195036 -0.14738171 -0.14350156 -0.14980789 -0.14463088 -0.24861306
 -0.16581029 -0.18216629 -0.13623556 -0.15175495 -0.15640161 -0.14150616
 -0.14167159 -0.14355386 -0.14997092 -0.32993996 -0.14222201 -0.21061639
 -0.15002384 -0.20376726 -0.15309211 -0.14199635 -0.38252251 -0.14139037
 -0.14001084 -0.13930563 -0.15069246 -0.15296996 -0.15487561 -0.13799171
 -0.16333985 -0.23086847 -0.15326565 -0.1380167  -0.15549487 -0.16520779
 -0.18363318 -0.14645892 -0.15348604 -0.15482693 -0.13822861 -0.16222447
 -0.15162362 -0.15499074 -0.16522274 -0.14255052 -0.16974172 -0.14562473
 -0.14140537 -0.14065906 -0.32406829 -0.14757181 -0.14345995 -0.1571481
 -0.13695797 -0.16838199 -0.15533595 -0.13839085 -0.14740932 -0.18720827
 -0.14193567 -0.14612555 -0.18898693 -0.14114959 -0.1685516  -0.18991362
 -0.15295413 -0.1530214  -0.14418327 -0.21248766 -0.14706615 -0.17518013
 -0.1744802  -0.14245863 -0.1582056  -0.1728824  -0.14864818 -0.13836712
 -0.16744227 -0.16541941 -0.17060618 -0.1539213  -0.15096985 -0.14321928
 -0.14994959 -0.16954397 -0.1415778  -0.14730099 -0.23473864 -0.19069675
 -0.16681599 -0.1935029  -0.1414426  -0.18931539 -0.17589951 -0.14953911
 -0.15729964 -0.15863824 -0.15660737 -0.20074815 -0.14320418 -0.1447965
 -0.19058787 -0.15649218 -0.14267852 -0.15350886 -0.14508821 -0.13743545
 -0.14403929 -0.13820733 -0.1369802  -0.15111648 -0.14075882 -0.17475169
 -0.19185271 -0.17148108 -0.18643894 -0.16210187 -0.16605844 -0.14436504
 -0.17503926 -0.19534343 -0.14372745 -0.15088984 -0.15062777 -0.15307509
 -0.14614468 -0.14078693 -0.15263806 -0.17185486 -0.13891143 -0.14970045
 -0.17410328 -0.16811423 -0.15184757 -0.15028634 -0.14794083 -0.14749607
 -0.15547899 -0.14316233 -0.1435863  -0.16099307 -0.15604391 -0.15879484
 -0.14893739 -0.1864139  -0.17882393 -0.15991055 -0.14611856 -0.17140785
 -0.14532456 -0.18290611 -0.14805815 -0.14249307 -0.15708758 -0.15298223
 -0.14461115 -0.17164222 -0.15610063 -0.14791709 -0.16872887 -0.13657766
 -0.36182201 -0.16986277 -0.17649653 -0.16225105 -0.14715172 -0.14560368
 -0.16156495 -0.15017028 -0.14656973 -0.14302594 -0.15696812 -0.1435122
 -0.17295842 -0.14421209 -0.1431108  -0.14442793 -0.14717533 -0.1686008
 -0.13980385 -0.15148889 -0.17153855 -0.19925788 -0.18645345 -0.13835116
 -0.17635291 -0.14929878 -0.19629006 -0.15256849 -0.15039934 -0.14462821
 -0.16498443 -0.15960092 -0.15772654 -0.15400289 -0.15244657 -0.17310539
 -0.15033102 -0.1510326  -0.18386306 -0.16428015 -0.14454098 -0.15144199
 -0.15120125 -0.13705296 -0.14577614 -0.19594713 -0.15737675 -0.13996692
 -0.14766624 -0.14202771 -0.16460681 -0.18645529 -0.15367136 -0.14182247
 -0.19263407 -0.15826549 -0.21243861 -0.16684981 -0.14176809 -0.14335903
 -0.1474362  -0.17374653 -0.14402004 -0.13838681 -0.20953427 -0.24299093
 -0.17239903 -0.14536094 -0.17425685 -0.14329385 -0.18114212 -0.17757137
 -0.14275291 -0.16282453 -0.13868131 -0.18142154 -0.15936867 -0.14235127
 -0.14636006 -0.13591022 -0.20995798 -0.13861858 -0.13906051 -0.19932501
 -0.14197947 -0.17452503 -0.13812709 -0.16096075 -0.16726389 -0.18205941
 -0.1559939  -0.19299414 -0.13654186 -0.1725192  -0.14146229 -0.15406841
 -0.14623134 -0.14002222 -0.14225388 -0.18582046 -0.1806515  -0.15179071
 -0.16020607 -0.19734954 -0.14857883 -0.14304762 -0.14433188 -0.14297495
 -0.1522982  -0.14641865 -0.1650447  -0.19262847 -0.14313835 -0.13953138
 -0.17620393 -0.15101669 -0.13880587 -0.2316431  -0.13641343 -0.14887712
 -0.14700676 -0.14381031 -0.17507706 -0.25440886 -0.14303851 -0.1487272
 -0.15360755 -0.14272703 -0.25872614 -0.20004488 -0.17735894 -0.144657
 -0.14555727 -0.16145713 -0.17993277 -0.14066867 -0.1435038  -0.17101408
 -0.14352993 -0.16890384 -0.13995041 -0.17185486 -0.14688027 -0.1707877
 -0.1373573  -0.13631717 -0.16065473 -0.14931799 -0.34876517 -0.1383191
 -0.14123113 -0.14606652 -0.15029095 -0.16655661 -0.17109937 -0.17837929
 -0.1408461  -0.19261754 -0.14423014 -0.15474815 -0.14515888 -0.14246986
 -0.14047849 -0.14129202 -0.13766547 -0.19399328 -0.1461044  -0.17912542
 -0.16428318 -0.16618006 -0.15253013 -0.14409701 -0.14449168 -0.16174396
 -0.2317452  -0.15369333 -0.13597916 -0.15849646 -0.14015614 -0.15239927
 -0.1401471  -0.14838939 -0.13970668 -0.15045889 -0.16112302 -0.14414297
 -0.14606511 -0.16766451 -0.14213815 -0.1441564  -0.38440428 -0.14462509
 -0.1435038  -0.14133749 -0.14634756 -0.14167519 -0.14269403 -0.15947663
 -0.15698156 -0.15027806 -0.14226582 -0.15157905 -0.16691126 -0.15113796
 -0.13859309 -0.15531031 -0.15314335 -0.25179581 -0.14072279 -0.18084036
 -0.1780198  -0.14615457 -0.16796298 -0.14606939 -0.14031122 -0.1487656
 -0.14519147 -0.14789625 -0.13506487 -0.16003055 -0.14450199 -0.14818551
 -0.15272148 -0.1366341  -0.14181681 -0.16876659 -0.17673769 -0.152301
 -0.14544889 -0.14030125 -0.14292098 -0.22407394 -0.15274491 -0.13683962
 -0.14244956 -0.15325059 -0.15394238 -0.16627798 -0.15571115 -0.14244543
 -0.14312324 -0.14310607 -0.14566882 -0.17122409 -0.19044106 -0.18476366
 -0.13797449 -0.14476025 -0.15817257 -0.16707399 -0.14478962 -0.15080213
 -0.15401696 -0.15072027 -0.14824887 -0.15688335 -0.13742592 -0.15620532
 -0.14819304 -0.15000964 -0.14380807 -0.15231958 -0.16185103 -0.17129049
 -0.1881897  -0.15242407 -0.13981648 -0.1682841  -0.1543893  -0.15776288
 -0.16764608 -0.20089894 -0.15313541 -0.1513646  -0.36556501 -0.14856019
 -0.14629822 -0.15054043 -0.16506213 -0.16338433 -0.15180879 -0.14579273
 -0.22187938 -0.16818102 -0.14120616 -0.13727921 -0.15464879 -0.18109259
 -0.16164333 -0.14302063 -0.13735507 -0.14883916 -0.19261754 -0.16012225
 -0.16334447 -0.15293064 -0.14375147 -0.1398489  -0.16916505 -0.13890634
 -0.14306944 -0.13727266 -0.1513594  -0.18234244 -0.15873084 -0.15060455
 -0.17456344 -0.19895117 -0.14349861 -0.23032887 -0.16905279 -0.14384384
 -0.16010015 -0.15266263 -0.13803491 -0.17798482 -0.14244091 -0.14824657
 -0.16342997 -0.35880616 -0.1452148  -0.16109497 -0.16085744 -0.16386256
 -0.17478696 -0.15262618 -0.14782726 -0.15140213 -0.15999286 -0.20223111
 -0.15923656 -0.14138765 -0.14056676 -0.14415311 -0.13920349 -0.14709862]
