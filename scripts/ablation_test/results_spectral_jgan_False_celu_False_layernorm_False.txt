Running RandomForest and LGBM for configuration 8/8:
=============================================
============ RF with GAN ============
Accuracy :  0.9259
Precision :  0.7692
Recall :  0.5882
f1-score :  0.6666
g_mean :  0.7571
auc :  0.7814
============ LGBM with JUNGAN ============
[LightGBM] [Info] Number of positive: 183, number of negative: 183
[LightGBM] [Info] Total Bins 596
[LightGBM] [Info] Number of data points in the train set: 366, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
Accuracy :  0.9111
Precision :  0.6923
Recall :  0.5294
f1-score :  0.6
g_mean :  0.7152
auc :  0.7478
